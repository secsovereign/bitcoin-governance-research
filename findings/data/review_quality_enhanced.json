{
  "temporal_trends": {
    "2012": {
      "total_reviews": 4,
      "avg_body_length": 1,
      "median_body_length": 0.0,
      "avg_word_count": 0.25,
      "avg_code_references": 0,
      "rubber_stamp_rate": 0.0,
      "question_rate": 0.0,
      "suggestion_rate": 0.0
    },
    "2013": {
      "total_reviews": 4,
      "avg_body_length": 0,
      "median_body_length": 0.0,
      "avg_word_count": 0,
      "avg_code_references": 0,
      "rubber_stamp_rate": 0.0,
      "question_rate": 0.0,
      "suggestion_rate": 0.0
    },
    "2014": {
      "total_reviews": 6,
      "avg_body_length": 11.333333333333334,
      "median_body_length": 0.0,
      "avg_word_count": 2.1666666666666665,
      "avg_code_references": 0,
      "rubber_stamp_rate": 0.0,
      "question_rate": 0.0,
      "suggestion_rate": 0.0
    },
    "2015": {
      "total_reviews": 10,
      "avg_body_length": 4.9,
      "median_body_length": 0.0,
      "avg_word_count": 1.2,
      "avg_code_references": 0,
      "rubber_stamp_rate": 0.0,
      "question_rate": 0.0,
      "suggestion_rate": 0.0
    },
    "2016": {
      "total_reviews": 885,
      "avg_body_length": 14.28135593220339,
      "median_body_length": 0,
      "avg_word_count": 0.9717514124293786,
      "avg_code_references": 0.005649717514124294,
      "rubber_stamp_rate": 0.07005649717514124,
      "question_rate": 0.0011299435028248588,
      "suggestion_rate": 0.003389830508474576
    },
    "2017": {
      "total_reviews": 5542,
      "avg_body_length": 28.032659689642728,
      "median_body_length": 0.0,
      "avg_word_count": 3.7215806568025984,
      "avg_code_references": 0.053229880909418985,
      "rubber_stamp_rate": 0.05178635871526525,
      "question_rate": 0.011909058101768314,
      "suggestion_rate": 0.02309635510645976
    },
    "2018": {
      "total_reviews": 6530,
      "avg_body_length": 35.04777947932619,
      "median_body_length": 0.0,
      "avg_word_count": 4.3183767228177645,
      "avg_code_references": 0.09433384379785605,
      "rubber_stamp_rate": 0.022817764165390504,
      "question_rate": 0.018529862174578866,
      "suggestion_rate": 0.03139356814701378
    },
    "2019": {
      "total_reviews": 7380,
      "avg_body_length": 72.90379403794039,
      "median_body_length": 0.0,
      "avg_word_count": 7.428184281842818,
      "avg_code_references": 0.1719512195121951,
      "rubber_stamp_rate": 0.00989159891598916,
      "question_rate": 0.023441734417344172,
      "suggestion_rate": 0.04403794037940379
    },
    "2020": {
      "total_reviews": 11732,
      "avg_body_length": 86.50042618479372,
      "median_body_length": 0.0,
      "avg_word_count": 9.051142175247188,
      "avg_code_references": 0.2265598363450392,
      "rubber_stamp_rate": 0.012359359018070235,
      "question_rate": 0.027446300715990454,
      "suggestion_rate": 0.048244118649846575
    },
    "2021": {
      "total_reviews": 11245,
      "avg_body_length": 131.4996887505558,
      "median_body_length": 0,
      "avg_word_count": 12.006758559359715,
      "avg_code_references": 0.3148065807025345,
      "rubber_stamp_rate": 0.013428190306803024,
      "question_rate": 0.028190306803023566,
      "suggestion_rate": 0.053712761227212094
    },
    "2022": {
      "total_reviews": 9926,
      "avg_body_length": 112.71972597219424,
      "median_body_length": 0.0,
      "avg_word_count": 10.886258311505138,
      "avg_code_references": 0.30304251460809994,
      "rubber_stamp_rate": 0.01934313923030425,
      "question_rate": 0.025690106790247833,
      "suggestion_rate": 0.045637719121499096
    },
    "2023": {
      "total_reviews": 10010,
      "avg_body_length": 112.56733266733266,
      "median_body_length": 0.0,
      "avg_word_count": 10.803796203796203,
      "avg_code_references": 0.25934065934065936,
      "rubber_stamp_rate": 0.012987012987012988,
      "question_rate": 0.029470529470529472,
      "suggestion_rate": 0.04785214785214785
    },
    "2024": {
      "total_reviews": 13660,
      "avg_body_length": 126.64751098096633,
      "median_body_length": 0.0,
      "avg_word_count": 12.145827232796487,
      "avg_code_references": 0.29465592972181553,
      "rubber_stamp_rate": 0.01288433382137628,
      "question_rate": 0.023792093704245974,
      "suggestion_rate": 0.04685212298682284
    },
    "2025": {
      "total_reviews": 12572,
      "avg_body_length": 153.21038816417436,
      "median_body_length": 0.0,
      "avg_word_count": 14.301384027998727,
      "avg_code_references": 0.3503022589882278,
      "rubber_stamp_rate": 0.0051702195354756605,
      "question_rate": 0.02664651606745148,
      "suggestion_rate": 0.055202036271078586
    }
  },
  "reviewer_profiles": {
    "all_reviewers": {
      "rebroad": {
        "total_reviews": 109,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "promag": {
        "total_reviews": 3252,
        "avg_body_length": 48.40159901599016,
        "avg_word_count": 6.178966789667896,
        "avg_code_references": 0.22386223862238622,
        "rubber_stamp_rate": 0.0012300123001230013,
        "question_rate": 0.07503075030750307,
        "suggestion_rate": 0.08241082410824108,
        "approval_rate": 0.0052275522755227555,
        "changes_requested_rate": 0.004305043050430504,
        "is_maintainer": true
      },
      "sjors": {
        "total_reviews": 2900,
        "avg_body_length": 89.71,
        "avg_word_count": 11.927586206896551,
        "avg_code_references": 0.4048275862068966,
        "rubber_stamp_rate": 0.001379310344827586,
        "question_rate": 0.04206896551724138,
        "suggestion_rate": 0.060689655172413794,
        "approval_rate": 0.07620689655172413,
        "changes_requested_rate": 0.00896551724137931,
        "is_maintainer": true
      },
      "fanquake": {
        "total_reviews": 2795,
        "avg_body_length": 195.31914132379248,
        "avg_word_count": 13.305903398926654,
        "avg_code_references": 0.3033989266547406,
        "rubber_stamp_rate": 0.0014311270125223613,
        "question_rate": 0.03005366726296959,
        "suggestion_rate": 0.03041144901610018,
        "approval_rate": 0.3323792486583184,
        "changes_requested_rate": 0.0064400715563506265,
        "is_maintainer": true
      },
      "thebluematt": {
        "total_reviews": 1046,
        "avg_body_length": 22.147227533460804,
        "avg_word_count": 3.372848948374761,
        "avg_code_references": 0.009560229445506692,
        "rubber_stamp_rate": 0.0019120458891013384,
        "question_rate": 0.0124282982791587,
        "suggestion_rate": 0.009560229445506692,
        "approval_rate": 0.006692160611854685,
        "changes_requested_rate": 0.0,
        "is_maintainer": true
      },
      "mruddy": {
        "total_reviews": 40,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "laanwj": {
        "total_reviews": 3039,
        "avg_body_length": 8.06778545574202,
        "avg_word_count": 0.8538993089832182,
        "avg_code_references": 0.022704837117472853,
        "rubber_stamp_rate": 0.009213557091148404,
        "question_rate": 0.0013162224415926291,
        "suggestion_rate": 0.002303389272787101,
        "approval_rate": 0.06186245475485357,
        "changes_requested_rate": 0.002303389272787101,
        "is_maintainer": true
      },
      "ryanofsky": {
        "total_reviews": 4495,
        "avg_body_length": 328.33882091212456,
        "avg_word_count": 38.53125695216907,
        "avg_code_references": 0.8863181312569521,
        "rubber_stamp_rate": 0.005339265850945495,
        "question_rate": 0.04471635150166852,
        "suggestion_rate": 0.27119021134593996,
        "approval_rate": 0.40155728587319245,
        "changes_requested_rate": 0.002224694104560623,
        "is_maintainer": true
      },
      "jonasschnelli": {
        "total_reviews": 907,
        "avg_body_length": 16.178610804851157,
        "avg_word_count": 1.0683572216097024,
        "avg_code_references": 0.013230429988974642,
        "rubber_stamp_rate": 0.013230429988974642,
        "question_rate": 0.0011025358324145535,
        "suggestion_rate": 0.004410143329658214,
        "approval_rate": 0.16207276736493936,
        "changes_requested_rate": 0.016538037486218304,
        "is_maintainer": true
      },
      "jnewbery": {
        "total_reviews": 3128,
        "avg_body_length": 57.429667519181585,
        "avg_word_count": 8.310102301790282,
        "avg_code_references": 0.1729539641943734,
        "rubber_stamp_rate": 0.0025575447570332483,
        "question_rate": 0.020460358056265986,
        "suggestion_rate": 0.06010230179028133,
        "approval_rate": 0.0079923273657289,
        "changes_requested_rate": 0.002877237851662404,
        "is_maintainer": true
      },
      "luke-jr": {
        "total_reviews": 1820,
        "avg_body_length": 21.34835164835165,
        "avg_word_count": 2.868131868131868,
        "avg_code_references": 0.04395604395604396,
        "rubber_stamp_rate": 0.06593406593406594,
        "question_rate": 0.026373626373626374,
        "suggestion_rate": 0.01978021978021978,
        "approval_rate": 0.11978021978021978,
        "changes_requested_rate": 0.1686813186813187,
        "is_maintainer": true
      },
      "meshcollider": {
        "total_reviews": 512,
        "avg_body_length": 91.25,
        "avg_word_count": 9.208984375,
        "avg_code_references": 0.044921875,
        "rubber_stamp_rate": 0.00390625,
        "question_rate": 0.013671875,
        "suggestion_rate": 0.03125,
        "approval_rate": 0.021484375,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "kallewoof": {
        "total_reviews": 1057,
        "avg_body_length": 14.98864711447493,
        "avg_word_count": 1.6906338694418164,
        "avg_code_references": 0.030274361400189215,
        "rubber_stamp_rate": 0.01892147587511826,
        "question_rate": 0.000946073793755913,
        "suggestion_rate": 0.007568590350047304,
        "approval_rate": 0.07473982970671712,
        "changes_requested_rate": 0.000946073793755913,
        "is_maintainer": false
      },
      "jeremyrubin": {
        "total_reviews": 587,
        "avg_body_length": 20.465076660988075,
        "avg_word_count": 3.4565587734241907,
        "avg_code_references": 0.010221465076660987,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0068143100511073255,
        "suggestion_rate": 0.022146507666098807,
        "approval_rate": 0.022146507666098807,
        "changes_requested_rate": 0.01192504258943782,
        "is_maintainer": false
      },
      "maflcko": {
        "total_reviews": 11465,
        "avg_body_length": 61.99877889228085,
        "avg_word_count": 3.632533798517226,
        "avg_code_references": 0.07614478848669864,
        "rubber_stamp_rate": 0.02511993022241605,
        "question_rate": 0.026951591801133885,
        "suggestion_rate": 0.011513301351940688,
        "approval_rate": 0.08102921936327954,
        "changes_requested_rate": 0.005756650675970344,
        "is_maintainer": true
      },
      "sipa": {
        "total_reviews": 4641,
        "avg_body_length": 6.509803921568627,
        "avg_word_count": 0.8465847877612583,
        "avg_code_references": 0.019392372333548805,
        "rubber_stamp_rate": 0.0010773540185304892,
        "question_rate": 0.002585649644473174,
        "suggestion_rate": 0.0030165912518853697,
        "approval_rate": 0.0030165912518853697,
        "changes_requested_rate": 0.0,
        "is_maintainer": true
      },
      "pedrobranco": {
        "total_reviews": 17,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "instagibbs": {
        "total_reviews": 2264,
        "avg_body_length": 31.7363074204947,
        "avg_word_count": 3.496024734982332,
        "avg_code_references": 0.04770318021201413,
        "rubber_stamp_rate": 0.007950530035335688,
        "question_rate": 0.007508833922261484,
        "suggestion_rate": 0.019434628975265017,
        "approval_rate": 0.09628975265017668,
        "changes_requested_rate": 0.004858657243816254,
        "is_maintainer": true
      },
      "dcousens": {
        "total_reviews": 262,
        "avg_body_length": 2.5877862595419847,
        "avg_word_count": 0.4389312977099237,
        "avg_code_references": 0.003816793893129771,
        "rubber_stamp_rate": 0.7022900763358778,
        "question_rate": 0.007633587786259542,
        "suggestion_rate": 0.007633587786259542,
        "approval_rate": 0.7748091603053435,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "practicalswift": {
        "total_reviews": 2001,
        "avg_body_length": 4.751124437781109,
        "avg_word_count": 0.5542228885557221,
        "avg_code_references": 0.0074962518740629685,
        "rubber_stamp_rate": 0.004497751124437781,
        "question_rate": 0.0014992503748125937,
        "suggestion_rate": 0.0034982508745627187,
        "approval_rate": 0.014492753623188406,
        "changes_requested_rate": 0.00849575212393803,
        "is_maintainer": false
      },
      "paveljanik": {
        "total_reviews": 223,
        "avg_body_length": 7.645739910313901,
        "avg_word_count": 0.39461883408071746,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.013452914798206279,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.08071748878923767,
        "changes_requested_rate": 0.02242152466367713,
        "is_maintainer": false
      },
      "morcos": {
        "total_reviews": 198,
        "avg_body_length": 11.808080808080808,
        "avg_word_count": 1.9696969696969697,
        "avg_code_references": 0.020202020202020204,
        "rubber_stamp_rate": 0.010101010101010102,
        "question_rate": 0.005050505050505051,
        "suggestion_rate": 0.010101010101010102,
        "approval_rate": 0.050505050505050504,
        "changes_requested_rate": 0.005050505050505051,
        "is_maintainer": false
      },
      "jtimon": {
        "total_reviews": 276,
        "avg_body_length": 4.565217391304348,
        "avg_word_count": 0.6630434782608695,
        "avg_code_references": 0.0036231884057971015,
        "rubber_stamp_rate": 0.025362318840579712,
        "question_rate": 0.0036231884057971015,
        "suggestion_rate": 0.0,
        "approval_rate": 0.03260869565217391,
        "changes_requested_rate": 0.007246376811594203,
        "is_maintainer": false
      },
      "mchrostowski": {
        "total_reviews": 13,
        "avg_body_length": 41.92307692307692,
        "avg_word_count": 6.6923076923076925,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.07692307692307693,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.15384615384615385,
        "is_maintainer": false
      },
      "gmaxwell": {
        "total_reviews": 349,
        "avg_body_length": 14.770773638968482,
        "avg_word_count": 2.332378223495702,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.27793696275071633,
        "question_rate": 0.008595988538681949,
        "suggestion_rate": 0.008595988538681949,
        "approval_rate": 0.3638968481375358,
        "changes_requested_rate": 0.0028653295128939827,
        "is_maintainer": true
      },
      "sdaftuar": {
        "total_reviews": 1196,
        "avg_body_length": 25.938127090301002,
        "avg_word_count": 4.326086956521739,
        "avg_code_references": 0.024247491638795988,
        "rubber_stamp_rate": 0.007525083612040134,
        "question_rate": 0.008361204013377926,
        "suggestion_rate": 0.021739130434782608,
        "approval_rate": 0.033444816053511704,
        "changes_requested_rate": 0.013377926421404682,
        "is_maintainer": false
      },
      "mrbandrews": {
        "total_reviews": 25,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jameshilliard": {
        "total_reviews": 27,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.037037037037037035,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.037037037037037035,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "christewart": {
        "total_reviews": 46,
        "avg_body_length": 20.608695652173914,
        "avg_word_count": 2.652173913043478,
        "avg_code_references": 0.06521739130434782,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.043478260869565216,
        "suggestion_rate": 0.0,
        "approval_rate": 0.043478260869565216,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "empact": {
        "total_reviews": 760,
        "avg_body_length": 1.9210526315789473,
        "avg_word_count": 0.10263157894736842,
        "avg_code_references": 0.002631578947368421,
        "rubber_stamp_rate": 0.005263157894736842,
        "question_rate": 0.0013157894736842105,
        "suggestion_rate": 0.0,
        "approval_rate": 0.018421052631578946,
        "changes_requested_rate": 0.0013157894736842105,
        "is_maintainer": false
      },
      "jimpo": {
        "total_reviews": 286,
        "avg_body_length": 22.74125874125874,
        "avg_word_count": 3.6783216783216783,
        "avg_code_references": 0.038461538461538464,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.017482517482517484,
        "suggestion_rate": 0.01048951048951049,
        "approval_rate": 0.01048951048951049,
        "changes_requested_rate": 0.0034965034965034965,
        "is_maintainer": false
      },
      "danra": {
        "total_reviews": 50,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.02,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.02,
        "changes_requested_rate": 0.06,
        "is_maintainer": false
      },
      "nicolasdorier": {
        "total_reviews": 167,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.005988023952095809,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.005988023952095809,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jl2012": {
        "total_reviews": 62,
        "avg_body_length": 0.6290322580645161,
        "avg_word_count": 0.0967741935483871,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.016129032258064516,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.06451612903225806,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jb55": {
        "total_reviews": 61,
        "avg_body_length": 48.75409836065574,
        "avg_word_count": 4.836065573770492,
        "avg_code_references": 0.04918032786885246,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.01639344262295082,
        "approval_rate": 0.19672131147540983,
        "changes_requested_rate": 0.04918032786885246,
        "is_maintainer": false
      },
      "theuni": {
        "total_reviews": 1152,
        "avg_body_length": 52.473958333333336,
        "avg_word_count": 6.878472222222222,
        "avg_code_references": 0.0954861111111111,
        "rubber_stamp_rate": 0.006944444444444444,
        "question_rate": 0.03993055555555555,
        "suggestion_rate": 0.029513888888888888,
        "approval_rate": 0.19618055555555555,
        "changes_requested_rate": 0.013888888888888888,
        "is_maintainer": true
      },
      "btcdrak": {
        "total_reviews": 17,
        "avg_body_length": 9,
        "avg_word_count": 0.5294117647058824,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.35294117647058826,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.5882352941176471,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "achow101": {
        "total_reviews": 4900,
        "avg_body_length": 5.571020408163266,
        "avg_word_count": 0.786530612244898,
        "avg_code_references": 0.011224489795918367,
        "rubber_stamp_rate": 0.0006122448979591836,
        "question_rate": 0.0022448979591836735,
        "suggestion_rate": 0.004489795918367347,
        "approval_rate": 0.004897959183673469,
        "changes_requested_rate": 0.00020408163265306123,
        "is_maintainer": true
      },
      "pstratem": {
        "total_reviews": 70,
        "avg_body_length": 1.5285714285714285,
        "avg_word_count": 0.2,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.014285714285714285,
        "approval_rate": 0.014285714285714285,
        "changes_requested_rate": 0.02857142857142857,
        "is_maintainer": false
      },
      "cryptaxe": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dexx7": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "petertodd": {
        "total_reviews": 26,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.07692307692307693,
        "is_maintainer": true
      },
      "murchandamus": {
        "total_reviews": 551,
        "avg_body_length": 68.02177858439201,
        "avg_word_count": 9.52087114337568,
        "avg_code_references": 0.12885662431941924,
        "rubber_stamp_rate": 0.003629764065335753,
        "question_rate": 0.018148820326678767,
        "suggestion_rate": 0.05807622504537205,
        "approval_rate": 0.039927404718693285,
        "changes_requested_rate": 0.0054446460980036296,
        "is_maintainer": false
      },
      "harding": {
        "total_reviews": 23,
        "avg_body_length": 194.82608695652175,
        "avg_word_count": 30.91304347826087,
        "avg_code_references": 0.2608695652173913,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.21739130434782608,
        "approval_rate": 0.08695652173913043,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ken2812221": {
        "total_reviews": 275,
        "avg_body_length": 8.309090909090909,
        "avg_word_count": 0.6,
        "avg_code_references": 0.01090909090909091,
        "rubber_stamp_rate": 0.014545454545454545,
        "question_rate": 0.0036363636363636364,
        "suggestion_rate": 0.01090909090909091,
        "approval_rate": 0.18181818181818182,
        "changes_requested_rate": 0.01818181818181818,
        "is_maintainer": false
      },
      "flack": {
        "total_reviews": 70,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "stevenroose": {
        "total_reviews": 17,
        "avg_body_length": 16.352941176470587,
        "avg_word_count": 2.9411764705882355,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.11764705882352941,
        "is_maintainer": false
      },
      "ethanheilman": {
        "total_reviews": 63,
        "avg_body_length": 3.2698412698412698,
        "avg_word_count": 0.4603174603174603,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.015873015873015872,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.047619047619047616,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dooglus": {
        "total_reviews": 40,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "eklitzke": {
        "total_reviews": 84,
        "avg_body_length": 44.54761904761905,
        "avg_word_count": 7.2976190476190474,
        "avg_code_references": 0.047619047619047616,
        "rubber_stamp_rate": 0.047619047619047616,
        "question_rate": 0.011904761904761904,
        "suggestion_rate": 0.023809523809523808,
        "approval_rate": 0.16666666666666666,
        "changes_requested_rate": 0.05952380952380952,
        "is_maintainer": false
      },
      "jamesob": {
        "total_reviews": 923,
        "avg_body_length": 355.2383531960997,
        "avg_word_count": 25.680390032502707,
        "avg_code_references": 0.6933911159263272,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.021668472372697724,
        "suggestion_rate": 0.03466955579631636,
        "approval_rate": 0.13759479956663057,
        "changes_requested_rate": 0.0010834236186348862,
        "is_maintainer": false
      },
      "cdecker": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ariard": {
        "total_reviews": 847,
        "avg_body_length": 144.3353010625738,
        "avg_word_count": 21.753246753246753,
        "avg_code_references": 0.526564344746163,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.08618654073199528,
        "suggestion_rate": 0.11097992916174734,
        "approval_rate": 0.06257378984651712,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "benma": {
        "total_reviews": 73,
        "avg_body_length": 3.4383561643835616,
        "avg_word_count": 0.5205479452054794,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0136986301369863,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0136986301369863,
        "changes_requested_rate": 0.0547945205479452,
        "is_maintainer": false
      },
      "pinheadmz": {
        "total_reviews": 531,
        "avg_body_length": 316.6949152542373,
        "avg_word_count": 20.037664783427495,
        "avg_code_references": 0.4783427495291902,
        "rubber_stamp_rate": 0.003766478342749529,
        "question_rate": 0.1487758945386064,
        "suggestion_rate": 0.04143126177024482,
        "approval_rate": 0.2033898305084746,
        "changes_requested_rate": 0.003766478342749529,
        "is_maintainer": false
      },
      "jimmysong": {
        "total_reviews": 66,
        "avg_body_length": 45.57575757575758,
        "avg_word_count": 6.712121212121212,
        "avg_code_references": 0.045454545454545456,
        "rubber_stamp_rate": 0.06060606060606061,
        "question_rate": 0.0,
        "suggestion_rate": 0.030303030303030304,
        "approval_rate": 0.19696969696969696,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "earonesty": {
        "total_reviews": 13,
        "avg_body_length": 7.615384615384615,
        "avg_word_count": 1.3076923076923077,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.07692307692307693,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.07692307692307693,
        "is_maintainer": false
      },
      "lontivero": {
        "total_reviews": 19,
        "avg_body_length": 18.94736842105263,
        "avg_word_count": 2.210526315789474,
        "avg_code_references": 0.10526315789473684,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.10526315789473684,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.10526315789473684,
        "is_maintainer": false
      },
      "tjps": {
        "total_reviews": 24,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "leishman": {
        "total_reviews": 17,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "rodentrabies": {
        "total_reviews": 33,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jlopp": {
        "total_reviews": 21,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ajtowns": {
        "total_reviews": 1414,
        "avg_body_length": 41.3974540311174,
        "avg_word_count": 6.084158415841584,
        "avg_code_references": 0.09193776520509193,
        "rubber_stamp_rate": 0.002828854314002829,
        "question_rate": 0.01768033946251768,
        "suggestion_rate": 0.0297029702970297,
        "approval_rate": 0.028288543140028287,
        "changes_requested_rate": 0.0049504950495049506,
        "is_maintainer": false
      },
      "aureleoules": {
        "total_reviews": 393,
        "avg_body_length": 214.12468193384223,
        "avg_word_count": 22.017811704834607,
        "avg_code_references": 0.5699745547073791,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.04834605597964377,
        "suggestion_rate": 0.027989821882951654,
        "approval_rate": 0.3435114503816794,
        "changes_requested_rate": 0.002544529262086514,
        "is_maintainer": false
      },
      "karelbilek": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "narula": {
        "total_reviews": 47,
        "avg_body_length": 5.829787234042553,
        "avg_word_count": 0.9361702127659575,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "conscott": {
        "total_reviews": 75,
        "avg_body_length": 42.82666666666667,
        "avg_word_count": 4.293333333333333,
        "avg_code_references": 0.14666666666666667,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.04,
        "suggestion_rate": 0.04,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "l2a5b1": {
        "total_reviews": 57,
        "avg_body_length": 57.73684210526316,
        "avg_word_count": 8.771929824561404,
        "avg_code_references": 0.43859649122807015,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03508771929824561,
        "suggestion_rate": 0.07017543859649122,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pierrerochard": {
        "total_reviews": 42,
        "avg_body_length": 9.452380952380953,
        "avg_word_count": 0.8333333333333334,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.023809523809523808,
        "changes_requested_rate": 0.023809523809523808,
        "is_maintainer": false
      },
      "greenaddress": {
        "total_reviews": 22,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pastapastapasta": {
        "total_reviews": 82,
        "avg_body_length": 93.07317073170732,
        "avg_word_count": 12.231707317073171,
        "avg_code_references": 0.06097560975609756,
        "rubber_stamp_rate": 0.024390243902439025,
        "question_rate": 0.06097560975609756,
        "suggestion_rate": 0.08536585365853659,
        "approval_rate": 0.3048780487804878,
        "changes_requested_rate": 0.08536585365853659,
        "is_maintainer": false
      },
      "arvidn": {
        "total_reviews": 21,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "mess110": {
        "total_reviews": 25,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "akionak": {
        "total_reviews": 73,
        "avg_body_length": 1.547945205479452,
        "avg_word_count": 0.2602739726027397,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0136986301369863,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0136986301369863,
        "changes_requested_rate": 0.0136986301369863,
        "is_maintainer": false
      },
      "glowang": {
        "total_reviews": 46,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "esotericnonsense": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "talkless": {
        "total_reviews": 42,
        "avg_body_length": 7.714285714285714,
        "avg_word_count": 0.9523809523809523,
        "avg_code_references": 0.023809523809523808,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.07142857142857142,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jonatack": {
        "total_reviews": 3973,
        "avg_body_length": 167.12031210672035,
        "avg_word_count": 17.668764158066953,
        "avg_code_references": 0.33274603574125344,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.022904606091115026,
        "suggestion_rate": 0.07676818525044048,
        "approval_rate": 0.012081550465643092,
        "changes_requested_rate": 0.0005033979360684622,
        "is_maintainer": true
      },
      "fjahr": {
        "total_reviews": 1392,
        "avg_body_length": 43.01652298850575,
        "avg_word_count": 6.558189655172414,
        "avg_code_references": 0.09339080459770115,
        "rubber_stamp_rate": 0.0014367816091954023,
        "question_rate": 0.015086206896551725,
        "suggestion_rate": 0.05100574712643678,
        "approval_rate": 0.02658045977011494,
        "changes_requested_rate": 0.0007183908045977011,
        "is_maintainer": false
      },
      "sipsorcery": {
        "total_reviews": 75,
        "avg_body_length": 6.333333333333333,
        "avg_word_count": 1.0133333333333334,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.24,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.30666666666666664,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "martinus": {
        "total_reviews": 251,
        "avg_body_length": 10.96812749003984,
        "avg_word_count": 1.302788844621514,
        "avg_code_references": 0.02390438247011952,
        "rubber_stamp_rate": 0.0199203187250996,
        "question_rate": 0.0,
        "suggestion_rate": 0.01195219123505976,
        "approval_rate": 0.05179282868525897,
        "changes_requested_rate": 0.00796812749003984,
        "is_maintainer": false
      },
      "glozow": {
        "total_reviews": 2498,
        "avg_body_length": 59.650520416333066,
        "avg_word_count": 8.244595676541232,
        "avg_code_references": 0.19935948759007205,
        "rubber_stamp_rate": 0.0012009607686148918,
        "question_rate": 0.03763010408326661,
        "suggestion_rate": 0.04643714971977582,
        "approval_rate": 0.0012009607686148918,
        "changes_requested_rate": 0.00040032025620496394,
        "is_maintainer": true
      },
      "darosior": {
        "total_reviews": 827,
        "avg_body_length": 96.85489721886336,
        "avg_word_count": 11.026602176541717,
        "avg_code_references": 0.20918984280532044,
        "rubber_stamp_rate": 0.0012091898428053204,
        "question_rate": 0.032648125755743655,
        "suggestion_rate": 0.02539298669891173,
        "approval_rate": 0.14026602176541716,
        "changes_requested_rate": 0.007255139056831923,
        "is_maintainer": false
      },
      "jsarenik": {
        "total_reviews": 13,
        "avg_body_length": 27.307692307692307,
        "avg_word_count": 3.923076923076923,
        "avg_code_references": 0.07692307692307693,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.15384615384615385,
        "changes_requested_rate": 0.07692307692307693,
        "is_maintainer": false
      },
      "hsjoberg": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "randolf": {
        "total_reviews": 107,
        "avg_body_length": 53.2803738317757,
        "avg_word_count": 7.542056074766355,
        "avg_code_references": 0.16822429906542055,
        "rubber_stamp_rate": 0.6728971962616822,
        "question_rate": 0.009345794392523364,
        "suggestion_rate": 0.018691588785046728,
        "approval_rate": 0.7757009345794392,
        "changes_requested_rate": 0.09345794392523364,
        "is_maintainer": false
      },
      "maaku": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jeffrade": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "skeees": {
        "total_reviews": 30,
        "avg_body_length": 45.93333333333333,
        "avg_word_count": 7.133333333333334,
        "avg_code_references": 0.13333333333333333,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.06666666666666667,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "donaloconnor": {
        "total_reviews": 32,
        "avg_body_length": 66.21875,
        "avg_word_count": 8.15625,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.03125,
        "question_rate": 0.0625,
        "suggestion_rate": 0.03125,
        "approval_rate": 0.28125,
        "changes_requested_rate": 0.09375,
        "is_maintainer": false
      },
      "dongcarl": {
        "total_reviews": 603,
        "avg_body_length": 16.04311774461028,
        "avg_word_count": 1.9917081260364842,
        "avg_code_references": 0.1044776119402985,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.004975124378109453,
        "suggestion_rate": 0.008291873963515755,
        "approval_rate": 0.008291873963515755,
        "changes_requested_rate": 0.009950248756218905,
        "is_maintainer": false
      },
      "fivepiece": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "rex4539": {
        "total_reviews": 22,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.045454545454545456,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.045454545454545456,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pierren": {
        "total_reviews": 32,
        "avg_body_length": 30.84375,
        "avg_word_count": 5.59375,
        "avg_code_references": 0.15625,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03125,
        "suggestion_rate": 0.03125,
        "approval_rate": 0.0625,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "kristapsk": {
        "total_reviews": 230,
        "avg_body_length": 43.56086956521739,
        "avg_word_count": 3.208695652173913,
        "avg_code_references": 0.02608695652173913,
        "rubber_stamp_rate": 0.004347826086956522,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.7086956521739131,
        "changes_requested_rate": 0.030434782608695653,
        "is_maintainer": false
      },
      "naumenkogs": {
        "total_reviews": 780,
        "avg_body_length": 4.143589743589744,
        "avg_word_count": 0.441025641025641,
        "avg_code_references": 0.002564102564102564,
        "rubber_stamp_rate": 0.001282051282051282,
        "question_rate": 0.001282051282051282,
        "suggestion_rate": 0.005128205128205128,
        "approval_rate": 0.02564102564102564,
        "changes_requested_rate": 0.0038461538461538464,
        "is_maintainer": false
      },
      "kiminuo": {
        "total_reviews": 308,
        "avg_body_length": 6.103896103896104,
        "avg_word_count": 0.8766233766233766,
        "avg_code_references": 0.03896103896103896,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.006493506493506494,
        "suggestion_rate": 0.006493506493506494,
        "approval_rate": 0.00974025974025974,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "vasild": {
        "total_reviews": 2975,
        "avg_body_length": 127.18050420168068,
        "avg_word_count": 13.345882352941176,
        "avg_code_references": 0.2984873949579832,
        "rubber_stamp_rate": 0.004033613445378151,
        "question_rate": 0.022857142857142857,
        "suggestion_rate": 0.031932773109243695,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.0016806722689075631,
        "is_maintainer": false
      },
      "romanz": {
        "total_reviews": 159,
        "avg_body_length": 19.28930817610063,
        "avg_word_count": 1.6666666666666667,
        "avg_code_references": 0.012578616352201259,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.006289308176100629,
        "approval_rate": 0.012578616352201259,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "murrayn": {
        "total_reviews": 21,
        "avg_body_length": 20.80952380952381,
        "avg_word_count": 2.380952380952381,
        "avg_code_references": 0.19047619047619047,
        "rubber_stamp_rate": 0.047619047619047616,
        "question_rate": 0.047619047619047616,
        "suggestion_rate": 0.047619047619047616,
        "approval_rate": 0.09523809523809523,
        "changes_requested_rate": 0.047619047619047616,
        "is_maintainer": false
      },
      "ccdle12": {
        "total_reviews": 20,
        "avg_body_length": 0.55,
        "avg_word_count": 0.1,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "sedited": {
        "total_reviews": 1384,
        "avg_body_length": 244.93930635838151,
        "avg_word_count": 8.291184971098266,
        "avg_code_references": 0.12427745664739884,
        "rubber_stamp_rate": 0.002890173410404624,
        "question_rate": 0.025289017341040464,
        "suggestion_rate": 0.02384393063583815,
        "approval_rate": 0.4638728323699422,
        "changes_requested_rate": 0.005780346820809248,
        "is_maintainer": false
      },
      "lucash-dev": {
        "total_reviews": 15,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "thestack": {
        "total_reviews": 1796,
        "avg_body_length": 190.41481069042317,
        "avg_word_count": 21.7739420935412,
        "avg_code_references": 0.6080178173719376,
        "rubber_stamp_rate": 0.0011135857461024498,
        "question_rate": 0.05902004454342984,
        "suggestion_rate": 0.10077951002227171,
        "approval_rate": 0.482739420935412,
        "changes_requested_rate": 0.007238307349665924,
        "is_maintainer": false
      },
      "hebasto": {
        "total_reviews": 5033,
        "avg_body_length": 170.16530896085834,
        "avg_word_count": 10.616928273395589,
        "avg_code_references": 0.3385654679117822,
        "rubber_stamp_rate": 0.0009934432743890324,
        "question_rate": 0.03934035366580568,
        "suggestion_rate": 0.04490363600238426,
        "approval_rate": 0.287502483608186,
        "changes_requested_rate": 0.016689847009735744,
        "is_maintainer": true
      },
      "w0xlt": {
        "total_reviews": 747,
        "avg_body_length": 94.40026773761714,
        "avg_word_count": 7.390896921017403,
        "avg_code_references": 0.27710843373493976,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.018741633199464525,
        "suggestion_rate": 0.03480589022757698,
        "approval_rate": 0.31459170013386883,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "docobitcoin": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 1.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 1.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "scravy": {
        "total_reviews": 55,
        "avg_body_length": 6.945454545454545,
        "avg_word_count": 0.8545454545454545,
        "avg_code_references": 0.03636363636363636,
        "rubber_stamp_rate": 0.14545454545454545,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.21818181818181817,
        "changes_requested_rate": 0.03636363636363636,
        "is_maintainer": false
      },
      "marcoagner": {
        "total_reviews": 24,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.041666666666666664,
        "is_maintainer": false
      },
      "leonardojobim": {
        "total_reviews": 14,
        "avg_body_length": 359.35714285714283,
        "avg_word_count": 33.42857142857143,
        "avg_code_references": 0.9285714285714286,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.6428571428571429,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "domob1812": {
        "total_reviews": 104,
        "avg_body_length": 7.028846153846154,
        "avg_word_count": 0.6730769230769231,
        "avg_code_references": 0.009615384615384616,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.009615384615384616,
        "approval_rate": 0.057692307692307696,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "leandrorocha84": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "real-or-random": {
        "total_reviews": 65,
        "avg_body_length": 72.64615384615385,
        "avg_word_count": 10.36923076923077,
        "avg_code_references": 0.2,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03076923076923077,
        "suggestion_rate": 0.046153846153846156,
        "approval_rate": 0.2153846153846154,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jarolrod": {
        "total_reviews": 362,
        "avg_body_length": 533.3646408839779,
        "avg_word_count": 42.96408839779006,
        "avg_code_references": 1.3977900552486189,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.058011049723756904,
        "suggestion_rate": 0.09668508287292818,
        "approval_rate": 0.19337016574585636,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "marcinja": {
        "total_reviews": 16,
        "avg_body_length": 11.375,
        "avg_word_count": 1.9375,
        "avg_code_references": 0.0625,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0625,
        "is_maintainer": false
      },
      "amitiuttarwar": {
        "total_reviews": 795,
        "avg_body_length": 46.89433962264151,
        "avg_word_count": 7.1169811320754715,
        "avg_code_references": 0.19119496855345913,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.010062893081761006,
        "suggestion_rate": 0.03270440251572327,
        "approval_rate": 0.013836477987421384,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "gwillen": {
        "total_reviews": 94,
        "avg_body_length": 0.39361702127659576,
        "avg_word_count": 0.06382978723404255,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "isghe": {
        "total_reviews": 28,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "am5800": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "fingera": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "tryphe": {
        "total_reviews": 17,
        "avg_body_length": 173.2941176470588,
        "avg_word_count": 23.705882352941178,
        "avg_code_references": 0.35294117647058826,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.058823529411764705,
        "suggestion_rate": 0.17647058823529413,
        "approval_rate": 0.11764705882352941,
        "changes_requested_rate": 0.058823529411764705,
        "is_maintainer": false
      },
      "ch4ot1c": {
        "total_reviews": 17,
        "avg_body_length": 1.2352941176470589,
        "avg_word_count": 0.17647058823529413,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.058823529411764705,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.17647058823529413,
        "is_maintainer": false
      },
      "etscrivner": {
        "total_reviews": 14,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "andrewtoth": {
        "total_reviews": 753,
        "avg_body_length": 13.810092961487383,
        "avg_word_count": 1.752988047808765,
        "avg_code_references": 0.05179282868525897,
        "rubber_stamp_rate": 0.0026560424966799467,
        "question_rate": 0.00796812749003984,
        "suggestion_rate": 0.009296148738379814,
        "approval_rate": 0.049136786188579015,
        "changes_requested_rate": 0.00398406374501992,
        "is_maintainer": false
      },
      "alexeyneu": {
        "total_reviews": 18,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "sanket1729": {
        "total_reviews": 31,
        "avg_body_length": 81.74193548387096,
        "avg_word_count": 11.193548387096774,
        "avg_code_references": 0.3225806451612903,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.2903225806451613,
        "changes_requested_rate": 0.06451612903225806,
        "is_maintainer": false
      },
      "merland": {
        "total_reviews": 34,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "brunoerg": {
        "total_reviews": 1296,
        "avg_body_length": 116.38271604938272,
        "avg_word_count": 9.255401234567902,
        "avg_code_references": 0.15432098765432098,
        "rubber_stamp_rate": 0.0023148148148148147,
        "question_rate": 0.008487654320987654,
        "suggestion_rate": 0.023919753086419752,
        "approval_rate": 0.23996913580246915,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dunxen": {
        "total_reviews": 48,
        "avg_body_length": 148.91666666666666,
        "avg_word_count": 9.166666666666666,
        "avg_code_references": 0.20833333333333334,
        "rubber_stamp_rate": 0.0625,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.4583333333333333,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "drahtbot": {
        "total_reviews": 51,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "larryruane": {
        "total_reviews": 217,
        "avg_body_length": 173.46543778801842,
        "avg_word_count": 23.23963133640553,
        "avg_code_references": 0.5668202764976958,
        "rubber_stamp_rate": 0.009216589861751152,
        "question_rate": 0.02304147465437788,
        "suggestion_rate": 0.17972350230414746,
        "approval_rate": 0.06451612903225806,
        "changes_requested_rate": 0.009216589861751152,
        "is_maintainer": false
      },
      "adamjonas": {
        "total_reviews": 66,
        "avg_body_length": 9.075757575757576,
        "avg_word_count": 1.2121212121212122,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.015151515151515152,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "saibato": {
        "total_reviews": 52,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.07692307692307693,
        "is_maintainer": false
      },
      "cvengler": {
        "total_reviews": 150,
        "avg_body_length": 4.526666666666666,
        "avg_word_count": 0.8133333333333334,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.006666666666666667,
        "changes_requested_rate": 0.006666666666666667,
        "is_maintainer": false
      },
      "nopara73": {
        "total_reviews": 13,
        "avg_body_length": 59.23076923076923,
        "avg_word_count": 7.769230769230769,
        "avg_code_references": 0.07692307692307693,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.15384615384615385,
        "approval_rate": 0.3076923076923077,
        "changes_requested_rate": 0.15384615384615385,
        "is_maintainer": false
      },
      "benthecarman": {
        "total_reviews": 131,
        "avg_body_length": 21.770992366412212,
        "avg_word_count": 1.4274809160305344,
        "avg_code_references": 0.03816793893129771,
        "rubber_stamp_rate": 0.022900763358778626,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.3435114503816794,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "crypt-iq": {
        "total_reviews": 274,
        "avg_body_length": 53.448905109489054,
        "avg_word_count": 7.405109489051095,
        "avg_code_references": 0.1897810218978102,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.021897810218978103,
        "suggestion_rate": 0.025547445255474453,
        "approval_rate": 0.010948905109489052,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "troygiorshev": {
        "total_reviews": 174,
        "avg_body_length": 16.683908045977013,
        "avg_word_count": 2.2758620689655173,
        "avg_code_references": 0.11494252873563218,
        "rubber_stamp_rate": 0.005747126436781609,
        "question_rate": 0.011494252873563218,
        "suggestion_rate": 0.028735632183908046,
        "approval_rate": 0.011494252873563218,
        "changes_requested_rate": 0.011494252873563218,
        "is_maintainer": false
      },
      "jkczyz": {
        "total_reviews": 79,
        "avg_body_length": 41.265822784810126,
        "avg_word_count": 6.569620253164557,
        "avg_code_references": 0.16455696202531644,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.05063291139240506,
        "suggestion_rate": 0.02531645569620253,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.02531645569620253,
        "is_maintainer": false
      },
      "mzumsande": {
        "total_reviews": 1508,
        "avg_body_length": 117.8236074270557,
        "avg_word_count": 18.066976127320956,
        "avg_code_references": 0.46684350132625996,
        "rubber_stamp_rate": 0.000663129973474801,
        "question_rate": 0.06830238726790451,
        "suggestion_rate": 0.10676392572944297,
        "approval_rate": 0.003978779840848806,
        "changes_requested_rate": 0.000663129973474801,
        "is_maintainer": false
      },
      "furszy": {
        "total_reviews": 1767,
        "avg_body_length": 110.70401810979061,
        "avg_word_count": 16.14883984153933,
        "avg_code_references": 0.32767402376910015,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.055461233729485006,
        "suggestion_rate": 0.07809847198641766,
        "approval_rate": 0.06960950764006792,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "stratospher": {
        "total_reviews": 430,
        "avg_body_length": 113.24186046511628,
        "avg_word_count": 14.011627906976743,
        "avg_code_references": 0.641860465116279,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03255813953488372,
        "suggestion_rate": 0.03953488372093023,
        "approval_rate": 0.011627906976744186,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "apoelstra": {
        "total_reviews": 20,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "kixunil": {
        "total_reviews": 27,
        "avg_body_length": 31.59259259259259,
        "avg_word_count": 4.851851851851852,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "fqlx": {
        "total_reviews": 24,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.041666666666666664,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.041666666666666664,
        "changes_requested_rate": 0.25,
        "is_maintainer": false
      },
      "elichai": {
        "total_reviews": 117,
        "avg_body_length": 24.88888888888889,
        "avg_word_count": 3.4444444444444446,
        "avg_code_references": 0.09401709401709402,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.02564102564102564,
        "approval_rate": 0.05128205128205128,
        "changes_requested_rate": 0.008547008547008548,
        "is_maintainer": false
      },
      "rajarshimaitra": {
        "total_reviews": 146,
        "avg_body_length": 187.75342465753425,
        "avg_word_count": 23.171232876712327,
        "avg_code_references": 0.5273972602739726,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0821917808219178,
        "suggestion_rate": 0.06164383561643835,
        "approval_rate": 0.08904109589041095,
        "changes_requested_rate": 0.02054794520547945,
        "is_maintainer": false
      },
      "dhruv": {
        "total_reviews": 293,
        "avg_body_length": 26.395904436860068,
        "avg_word_count": 3.2320819112627985,
        "avg_code_references": 0.11604095563139932,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.006825938566552901,
        "suggestion_rate": 0.006825938566552901,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jachiang": {
        "total_reviews": 26,
        "avg_body_length": 19.192307692307693,
        "avg_word_count": 2.8846153846153846,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.038461538461538464,
        "changes_requested_rate": 0.038461538461538464,
        "is_maintainer": false
      },
      "decryp2kanon": {
        "total_reviews": 12,
        "avg_body_length": 1.9166666666666667,
        "avg_word_count": 0.3333333333333333,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.16666666666666666,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.25,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dergoegge": {
        "total_reviews": 861,
        "avg_body_length": 58.05458768873403,
        "avg_word_count": 6.809523809523809,
        "avg_code_references": 0.11033681765389082,
        "rubber_stamp_rate": 0.003484320557491289,
        "question_rate": 0.023228803716608595,
        "suggestion_rate": 0.036004645760743324,
        "approval_rate": 0.3240418118466899,
        "changes_requested_rate": 0.020905923344947737,
        "is_maintainer": false
      },
      "bushstar": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "prusnak": {
        "total_reviews": 86,
        "avg_body_length": 18.453488372093023,
        "avg_word_count": 1.9069767441860466,
        "avg_code_references": 0.10465116279069768,
        "rubber_stamp_rate": 0.05813953488372093,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.38372093023255816,
        "changes_requested_rate": 0.09302325581395349,
        "is_maintainer": false
      },
      "icota": {
        "total_reviews": 41,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.04878048780487805,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.04878048780487805,
        "changes_requested_rate": 0.14634146341463414,
        "is_maintainer": false
      },
      "jonasnick": {
        "total_reviews": 12,
        "avg_body_length": 80.33333333333333,
        "avg_word_count": 7.916666666666667,
        "avg_code_references": 0.08333333333333333,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.08333333333333333,
        "approval_rate": 0.3333333333333333,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "gertjaap": {
        "total_reviews": 16,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "junderw": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "michaelfolkson": {
        "total_reviews": 55,
        "avg_body_length": 34.27272727272727,
        "avg_word_count": 5.290909090909091,
        "avg_code_references": 0.01818181818181818,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.01818181818181818,
        "suggestion_rate": 0.05454545454545454,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ezegom": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "remagpie": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "hodlinator": {
        "total_reviews": 1032,
        "avg_body_length": 327.30232558139534,
        "avg_word_count": 35.406007751937985,
        "avg_code_references": 1.4021317829457365,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0562015503875969,
        "suggestion_rate": 0.12790697674418605,
        "approval_rate": 0.23352713178294573,
        "changes_requested_rate": 0.016472868217054265,
        "is_maintainer": false
      },
      "l0rinc": {
        "total_reviews": 2201,
        "avg_body_length": 256.540208995911,
        "avg_word_count": 26.194457064970468,
        "avg_code_references": 0.2371649250340754,
        "rubber_stamp_rate": 0.011812812358019082,
        "question_rate": 0.030895047705588367,
        "suggestion_rate": 0.0595184007269423,
        "approval_rate": 0.07223989095865516,
        "changes_requested_rate": 0.04770558836892322,
        "is_maintainer": false
      },
      "felipsoarez": {
        "total_reviews": 23,
        "avg_body_length": 24.82608695652174,
        "avg_word_count": 4.434782608695652,
        "avg_code_references": 0.043478260869565216,
        "rubber_stamp_rate": 0.043478260869565216,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.043478260869565216,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "gchuf": {
        "total_reviews": 22,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "davereikher": {
        "total_reviews": 33,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.030303030303030304,
        "is_maintainer": false
      },
      "0xb10c": {
        "total_reviews": 198,
        "avg_body_length": 109.32828282828282,
        "avg_word_count": 11.97979797979798,
        "avg_code_references": 0.4898989898989899,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.015151515151515152,
        "suggestion_rate": 0.06060606060606061,
        "approval_rate": 0.08585858585858586,
        "changes_requested_rate": 0.030303030303030304,
        "is_maintainer": false
      },
      "stickies-v": {
        "total_reviews": 1408,
        "avg_body_length": 287.7052556818182,
        "avg_word_count": 34.15625,
        "avg_code_references": 0.6796875,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.08096590909090909,
        "suggestion_rate": 0.10085227272727272,
        "approval_rate": 0.3039772727272727,
        "changes_requested_rate": 0.0014204545454545455,
        "is_maintainer": false
      },
      "randymcmillan": {
        "total_reviews": 59,
        "avg_body_length": 6.813559322033898,
        "avg_word_count": 0.6949152542372882,
        "avg_code_references": 0.01694915254237288,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.01694915254237288,
        "suggestion_rate": 0.01694915254237288,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.03389830508474576,
        "is_maintainer": false
      },
      "zero-1729": {
        "total_reviews": 163,
        "avg_body_length": 220.19631901840492,
        "avg_word_count": 23.521472392638035,
        "avg_code_references": 0.852760736196319,
        "rubber_stamp_rate": 0.012269938650306749,
        "question_rate": 0.006134969325153374,
        "suggestion_rate": 0.0736196319018405,
        "approval_rate": 0.31901840490797545,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "willcl-ark": {
        "total_reviews": 544,
        "avg_body_length": 208.18566176470588,
        "avg_word_count": 20.066176470588236,
        "avg_code_references": 0.41911764705882354,
        "rubber_stamp_rate": 0.014705882352941176,
        "question_rate": 0.05698529411764706,
        "suggestion_rate": 0.058823529411764705,
        "approval_rate": 0.35294117647058826,
        "changes_requested_rate": 0.003676470588235294,
        "is_maintainer": false
      },
      "john-moffett": {
        "total_reviews": 58,
        "avg_body_length": 226.43103448275863,
        "avg_word_count": 26.051724137931036,
        "avg_code_references": 0.41379310344827586,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.10344827586206896,
        "approval_rate": 0.6551724137931034,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ysangkok": {
        "total_reviews": 22,
        "avg_body_length": 5.045454545454546,
        "avg_word_count": 0.7727272727272727,
        "avg_code_references": 0.045454545454545456,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.045454545454545456,
        "is_maintainer": false
      },
      "za-kk": {
        "total_reviews": 24,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "carnhofdaki": {
        "total_reviews": 17,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "katesalazar": {
        "total_reviews": 44,
        "avg_body_length": 4.840909090909091,
        "avg_word_count": 0.7954545454545454,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.022727272727272728,
        "question_rate": 0.022727272727272728,
        "suggestion_rate": 0.0,
        "approval_rate": 0.022727272727272728,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "brakmic": {
        "total_reviews": 164,
        "avg_body_length": 0.524390243902439,
        "avg_word_count": 0.09146341463414634,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.006097560975609756,
        "changes_requested_rate": 0.006097560975609756,
        "is_maintainer": false
      },
      "paymog": {
        "total_reviews": 18,
        "avg_body_length": 107.83333333333333,
        "avg_word_count": 14.166666666666666,
        "avg_code_references": 0.05555555555555555,
        "rubber_stamp_rate": 0.05555555555555555,
        "question_rate": 0.1111111111111111,
        "suggestion_rate": 0.0,
        "approval_rate": 0.16666666666666666,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "eriknylund": {
        "total_reviews": 39,
        "avg_body_length": 22.17948717948718,
        "avg_word_count": 3.7435897435897436,
        "avg_code_references": 0.1282051282051282,
        "rubber_stamp_rate": 0.07692307692307693,
        "question_rate": 0.0,
        "suggestion_rate": 0.02564102564102564,
        "approval_rate": 0.1282051282051282,
        "changes_requested_rate": 0.07692307692307693,
        "is_maintainer": false
      },
      "riccardomasutti": {
        "total_reviews": 32,
        "avg_body_length": 14.71875,
        "avg_word_count": 2.375,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.21875,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.8125,
        "changes_requested_rate": 0.15625,
        "is_maintainer": false
      },
      "robot-visions": {
        "total_reviews": 15,
        "avg_body_length": 172.2,
        "avg_word_count": 19,
        "avg_code_references": 0.7333333333333333,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.06666666666666667,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cculianu": {
        "total_reviews": 14,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "yusufsahinhamza": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dangershony": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "yancyribbens": {
        "total_reviews": 157,
        "avg_body_length": 0.2929936305732484,
        "avg_word_count": 0.050955414012738856,
        "avg_code_references": 0.006369426751592357,
        "rubber_stamp_rate": 0.006369426751592357,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.006369426751592357,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "bvbfan": {
        "total_reviews": 18,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "n-thumann": {
        "total_reviews": 23,
        "avg_body_length": 14.91304347826087,
        "avg_word_count": 2.217391304347826,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.08695652173913043,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.21739130434782608,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "s3rk": {
        "total_reviews": 298,
        "avg_body_length": 33.738255033557046,
        "avg_word_count": 5.385906040268456,
        "avg_code_references": 0.087248322147651,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.026845637583892617,
        "suggestion_rate": 0.026845637583892617,
        "approval_rate": 0.010067114093959731,
        "changes_requested_rate": 0.003355704697986577,
        "is_maintainer": false
      },
      "nivelion": {
        "total_reviews": 11,
        "avg_body_length": 10.909090909090908,
        "avg_word_count": 1.2727272727272727,
        "avg_code_references": 0.09090909090909091,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ronsherfey": {
        "total_reviews": 13,
        "avg_body_length": 12.307692307692308,
        "avg_word_count": 1.8461538461538463,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.38461538461538464,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.0,
        "approval_rate": 0.5384615384615384,
        "changes_requested_rate": 0.23076923076923078,
        "is_maintainer": false
      },
      "robot-dreams": {
        "total_reviews": 18,
        "avg_body_length": 62.94444444444444,
        "avg_word_count": 9.11111111111111,
        "avg_code_references": 0.2777777777777778,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.05555555555555555,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "mjdietzx": {
        "total_reviews": 186,
        "avg_body_length": 62.02150537634409,
        "avg_word_count": 9.349462365591398,
        "avg_code_references": 0.15591397849462366,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.016129032258064516,
        "suggestion_rate": 0.016129032258064516,
        "approval_rate": 0.06451612903225806,
        "changes_requested_rate": 0.005376344086021506,
        "is_maintainer": false
      },
      "kouloumos": {
        "total_reviews": 80,
        "avg_body_length": 324,
        "avg_word_count": 39.3125,
        "avg_code_references": 1.5125,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.1125,
        "suggestion_rate": 0.1625,
        "approval_rate": 0.0125,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ismaelsadeeq": {
        "total_reviews": 935,
        "avg_body_length": 160.64171122994654,
        "avg_word_count": 17.023529411764706,
        "avg_code_references": 0.413903743315508,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.026737967914438502,
        "suggestion_rate": 0.04171122994652406,
        "approval_rate": 0.06737967914438503,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "vincenzopalazzo": {
        "total_reviews": 134,
        "avg_body_length": 94.44776119402985,
        "avg_word_count": 6.134328358208955,
        "avg_code_references": 0.022388059701492536,
        "rubber_stamp_rate": 0.007462686567164179,
        "question_rate": 0.014925373134328358,
        "suggestion_rate": 0.029850746268656716,
        "approval_rate": 0.4925373134328358,
        "changes_requested_rate": 0.022388059701492536,
        "is_maintainer": false
      },
      "kcalvinalvin": {
        "total_reviews": 33,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "t-bast": {
        "total_reviews": 109,
        "avg_body_length": 71.73394495412845,
        "avg_word_count": 8.330275229357799,
        "avg_code_references": 0.09174311926605505,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.009174311926605505,
        "suggestion_rate": 0.01834862385321101,
        "approval_rate": 0.21100917431192662,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "shubhampalriwala": {
        "total_reviews": 28,
        "avg_body_length": 94.78571428571429,
        "avg_word_count": 14.535714285714286,
        "avg_code_references": 0.21428571428571427,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03571428571428571,
        "suggestion_rate": 0.07142857142857142,
        "approval_rate": 0.07142857142857142,
        "changes_requested_rate": 0.03571428571428571,
        "is_maintainer": false
      },
      "pg156": {
        "total_reviews": 10,
        "avg_body_length": 174.1,
        "avg_word_count": 20.5,
        "avg_code_references": 0.5,
        "rubber_stamp_rate": 0.1,
        "question_rate": 0.1,
        "suggestion_rate": 0.1,
        "approval_rate": 0.1,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "am1r021": {
        "total_reviews": 10,
        "avg_body_length": 4.4,
        "avg_word_count": 0.7,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "stackman27": {
        "total_reviews": 66,
        "avg_body_length": 25.136363636363637,
        "avg_word_count": 3.5303030303030303,
        "avg_code_references": 0.22727272727272727,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.045454545454545456,
        "suggestion_rate": 0.0,
        "approval_rate": 0.015151515151515152,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "amovfx": {
        "total_reviews": 27,
        "avg_body_length": 290.7037037037037,
        "avg_word_count": 26.77777777777778,
        "avg_code_references": 0.2222222222222222,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.14814814814814814,
        "suggestion_rate": 0.037037037037037035,
        "approval_rate": 0.07407407407407407,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "guggero": {
        "total_reviews": 14,
        "avg_body_length": 149.71428571428572,
        "avg_word_count": 20.571428571428573,
        "avg_code_references": 0.8571428571428571,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.14285714285714285,
        "suggestion_rate": 0.14285714285714285,
        "approval_rate": 0.21428571428571427,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "slmtpz": {
        "total_reviews": 18,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "gruve-p": {
        "total_reviews": 21,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.047619047619047616,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.047619047619047616,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "rspigler": {
        "total_reviews": 46,
        "avg_body_length": 3.152173913043478,
        "avg_word_count": 0.32608695652173914,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.021739130434782608,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "sr-gi": {
        "total_reviews": 308,
        "avg_body_length": 36.077922077922075,
        "avg_word_count": 4.412337662337662,
        "avg_code_references": 0.1266233766233766,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.012987012987012988,
        "suggestion_rate": 0.003246753246753247,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.003246753246753247,
        "is_maintainer": false
      },
      "lsilva01": {
        "total_reviews": 189,
        "avg_body_length": 72.72486772486772,
        "avg_word_count": 7.502645502645502,
        "avg_code_references": 0.41798941798941797,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.010582010582010581,
        "suggestion_rate": 0.021164021164021163,
        "approval_rate": 0.42857142857142855,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "bitcointsunami": {
        "total_reviews": 20,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "nginocchio": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "satsie": {
        "total_reviews": 18,
        "avg_body_length": 160.66666666666666,
        "avg_word_count": 17,
        "avg_code_references": 0.8333333333333334,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.05555555555555555,
        "suggestion_rate": 0.0,
        "approval_rate": 0.1111111111111111,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dariusparvin": {
        "total_reviews": 19,
        "avg_body_length": 54.578947368421055,
        "avg_word_count": 8.473684210526315,
        "avg_code_references": 0.42105263157894735,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.05263157894736842,
        "suggestion_rate": 0.2631578947368421,
        "approval_rate": 0.05263157894736842,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "danben": {
        "total_reviews": 16,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "fyquah": {
        "total_reviews": 17,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ivanacostarubio": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jaonoctus": {
        "total_reviews": 15,
        "avg_body_length": 93.13333333333334,
        "avg_word_count": 13.733333333333333,
        "avg_code_references": 0.13333333333333333,
        "rubber_stamp_rate": 0.2,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.4,
        "changes_requested_rate": 0.13333333333333333,
        "is_maintainer": false
      },
      "reemuru": {
        "total_reviews": 15,
        "avg_body_length": 23,
        "avg_word_count": 2.6666666666666665,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.2,
        "question_rate": 0.0,
        "suggestion_rate": 0.06666666666666667,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "klementtan": {
        "total_reviews": 117,
        "avg_body_length": 65.34188034188034,
        "avg_word_count": 5.615384615384615,
        "avg_code_references": 0.39316239316239315,
        "rubber_stamp_rate": 0.05128205128205128,
        "question_rate": 0.0,
        "suggestion_rate": 0.017094017094017096,
        "approval_rate": 0.20512820512820512,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "windsok": {
        "total_reviews": 17,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "subawit": {
        "total_reviews": 10,
        "avg_body_length": 0.2,
        "avg_word_count": 0.2,
        "avg_code_references": 0,
        "rubber_stamp_rate": 1.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 1.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "amadeuszpawlik": {
        "total_reviews": 36,
        "avg_body_length": 28.63888888888889,
        "avg_word_count": 4.333333333333333,
        "avg_code_references": 0.3055555555555556,
        "rubber_stamp_rate": 0.027777777777777776,
        "question_rate": 0.027777777777777776,
        "suggestion_rate": 0.0,
        "approval_rate": 0.08333333333333333,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "josibake": {
        "total_reviews": 477,
        "avg_body_length": 98.32494758909853,
        "avg_word_count": 11.09853249475891,
        "avg_code_references": 0.22012578616352202,
        "rubber_stamp_rate": 0.012578616352201259,
        "question_rate": 0.018867924528301886,
        "suggestion_rate": 0.07127882599580712,
        "approval_rate": 0.07547169811320754,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "sriramdvt": {
        "total_reviews": 11,
        "avg_body_length": 35.54545454545455,
        "avg_word_count": 4.090909090909091,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.09090909090909091,
        "changes_requested_rate": 0.09090909090909091,
        "is_maintainer": false
      },
      "shaavan": {
        "total_reviews": 321,
        "avg_body_length": 474.10280373831773,
        "avg_word_count": 63.90965732087228,
        "avg_code_references": 1.7445482866043613,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0778816199376947,
        "suggestion_rate": 0.2523364485981308,
        "approval_rate": 0.514018691588785,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "whitslack": {
        "total_reviews": 14,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "nikhilbartwal": {
        "total_reviews": 15,
        "avg_body_length": 52.8,
        "avg_word_count": 7.333333333333333,
        "avg_code_references": 0.3333333333333333,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.06666666666666667,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pk-b2": {
        "total_reviews": 18,
        "avg_body_length": 25.055555555555557,
        "avg_word_count": 2.388888888888889,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.2222222222222222,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cacrowley": {
        "total_reviews": 10,
        "avg_body_length": 0.6,
        "avg_word_count": 0.1,
        "avg_code_references": 0.1,
        "rubber_stamp_rate": 0.9,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.9,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cbergqvist": {
        "total_reviews": 93,
        "avg_body_length": 263.0430107526882,
        "avg_word_count": 32.645161290322584,
        "avg_code_references": 1.8064516129032258,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.043010752688172046,
        "suggestion_rate": 0.15053763440860216,
        "approval_rate": 0.40860215053763443,
        "changes_requested_rate": 0.043010752688172046,
        "is_maintainer": false
      },
      "ishaanam": {
        "total_reviews": 330,
        "avg_body_length": 28.912121212121214,
        "avg_word_count": 4.1454545454545455,
        "avg_code_references": 0.0696969696969697,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.006060606060606061,
        "suggestion_rate": 0.024242424242424242,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "dougefresh": {
        "total_reviews": 63,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "hernanmarino": {
        "total_reviews": 95,
        "avg_body_length": 65.51578947368421,
        "avg_word_count": 9,
        "avg_code_references": 0.05263157894736842,
        "rubber_stamp_rate": 0.12631578947368421,
        "question_rate": 0.042105263157894736,
        "suggestion_rate": 0.08421052631578947,
        "approval_rate": 0.45263157894736844,
        "changes_requested_rate": 0.010526315789473684,
        "is_maintainer": false
      },
      "pablomartin4btc": {
        "total_reviews": 564,
        "avg_body_length": 229.06205673758865,
        "avg_word_count": 23.914893617021278,
        "avg_code_references": 0.9964539007092199,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.09042553191489362,
        "suggestion_rate": 0.11347517730496454,
        "approval_rate": 0.14893617021276595,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "vostrnad": {
        "total_reviews": 13,
        "avg_body_length": 304,
        "avg_word_count": 43.38461538461539,
        "avg_code_references": 0.5384615384615384,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.23076923076923078,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.15384615384615385,
        "is_maintainer": false
      },
      "sstone": {
        "total_reviews": 74,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "kevinmusgrave": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "danielabrozzoni": {
        "total_reviews": 125,
        "avg_body_length": 268.064,
        "avg_word_count": 32.008,
        "avg_code_references": 0.672,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.032,
        "suggestion_rate": 0.04,
        "approval_rate": 0.304,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ayush933": {
        "total_reviews": 15,
        "avg_body_length": 3.3333333333333335,
        "avg_word_count": 0.5333333333333333,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.06666666666666667,
        "is_maintainer": false
      },
      "m3dwards": {
        "total_reviews": 100,
        "avg_body_length": 17.42,
        "avg_word_count": 1.81,
        "avg_code_references": 0.11,
        "rubber_stamp_rate": 0.02,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.02,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "eunoia1729": {
        "total_reviews": 13,
        "avg_body_length": 7.461538461538462,
        "avg_word_count": 1.6153846153846154,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "portlandhodl": {
        "total_reviews": 39,
        "avg_body_length": 2.5128205128205128,
        "avg_word_count": 0.38461538461538464,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.07692307692307693,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.02564102564102564,
        "is_maintainer": false
      },
      "rnapoles": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "scgbckbone": {
        "total_reviews": 10,
        "avg_body_length": 76.9,
        "avg_word_count": 10.6,
        "avg_code_references": 0.7,
        "rubber_stamp_rate": 0.2,
        "question_rate": 0.1,
        "suggestion_rate": 0.0,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "riahiamirreza": {
        "total_reviews": 29,
        "avg_body_length": 2,
        "avg_word_count": 0.3448275862068966,
        "avg_code_references": 0.06896551724137931,
        "rubber_stamp_rate": 0.3448275862068966,
        "question_rate": 0.034482758620689655,
        "suggestion_rate": 0.0,
        "approval_rate": 0.3448275862068966,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "chinggg": {
        "total_reviews": 24,
        "avg_body_length": 9.333333333333334,
        "avg_word_count": 0.9583333333333334,
        "avg_code_references": 0.08333333333333333,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.041666666666666664,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "kevkevinpal": {
        "total_reviews": 255,
        "avg_body_length": 14.31764705882353,
        "avg_word_count": 1.6666666666666667,
        "avg_code_references": 0.08627450980392157,
        "rubber_stamp_rate": 0.00392156862745098,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.027450980392156862,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "virtu": {
        "total_reviews": 18,
        "avg_body_length": 43.888888888888886,
        "avg_word_count": 3.388888888888889,
        "avg_code_references": 0.16666666666666666,
        "rubber_stamp_rate": 0.05555555555555555,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.05555555555555555,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "davidgumberg": {
        "total_reviews": 288,
        "avg_body_length": 69.26041666666667,
        "avg_word_count": 6.940972222222222,
        "avg_code_references": 0.2604166666666667,
        "rubber_stamp_rate": 0.003472222222222222,
        "question_rate": 0.003472222222222222,
        "suggestion_rate": 0.010416666666666666,
        "approval_rate": 0.03819444444444445,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "brandonodiwuor": {
        "total_reviews": 263,
        "avg_body_length": 113.26996197718631,
        "avg_word_count": 9.041825095057034,
        "avg_code_references": 0.5171102661596958,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0038022813688212928,
        "suggestion_rate": 0.011406844106463879,
        "approval_rate": 0.2661596958174905,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "marnixcroes": {
        "total_reviews": 26,
        "avg_body_length": 52.15384615384615,
        "avg_word_count": 4.923076923076923,
        "avg_code_references": 0.15384615384615385,
        "rubber_stamp_rate": 0.15384615384615385,
        "question_rate": 0.11538461538461539,
        "suggestion_rate": 0.0,
        "approval_rate": 0.38461538461538464,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "tdb3": {
        "total_reviews": 501,
        "avg_body_length": 446.560878243513,
        "avg_word_count": 40.942115768463076,
        "avg_code_references": 1.18562874251497,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03792415169660679,
        "suggestion_rate": 0.0718562874251497,
        "approval_rate": 0.4750499001996008,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "marcofleon": {
        "total_reviews": 245,
        "avg_body_length": 251.1469387755102,
        "avg_word_count": 25.39183673469388,
        "avg_code_references": 0.8448979591836735,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.036734693877551024,
        "suggestion_rate": 0.061224489795918366,
        "approval_rate": 0.08979591836734693,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "miles170": {
        "total_reviews": 19,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "benwestgate": {
        "total_reviews": 17,
        "avg_body_length": 180.94117647058823,
        "avg_word_count": 22.352941176470587,
        "avg_code_references": 0.8235294117647058,
        "rubber_stamp_rate": 0.058823529411764705,
        "question_rate": 0.058823529411764705,
        "suggestion_rate": 0.0,
        "approval_rate": 0.058823529411764705,
        "changes_requested_rate": 0.058823529411764705,
        "is_maintainer": false
      },
      "eunovo": {
        "total_reviews": 193,
        "avg_body_length": 43.06217616580311,
        "avg_word_count": 4.476683937823834,
        "avg_code_references": 0.10880829015544041,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.010362694300518135,
        "approval_rate": 0.015544041450777202,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "rkrux": {
        "total_reviews": 580,
        "avg_body_length": 324.93793103448274,
        "avg_word_count": 36.62413793103448,
        "avg_code_references": 1.1258620689655172,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.06724137931034482,
        "suggestion_rate": 0.14655172413793102,
        "approval_rate": 0.3620689655172414,
        "changes_requested_rate": 0.015517241379310345,
        "is_maintainer": false
      },
      "naiyoma": {
        "total_reviews": 90,
        "avg_body_length": 188.75555555555556,
        "avg_word_count": 17.933333333333334,
        "avg_code_references": 0.5444444444444444,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.011111111111111112,
        "suggestion_rate": 0.06666666666666667,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "denavila": {
        "total_reviews": 14,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "bigspider": {
        "total_reviews": 11,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ayush170-future": {
        "total_reviews": 31,
        "avg_body_length": 15.193548387096774,
        "avg_word_count": 2.7096774193548385,
        "avg_code_references": 0.03225806451612903,
        "rubber_stamp_rate": 0.12903225806451613,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.2903225806451613,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "alexanderwiederin": {
        "total_reviews": 19,
        "avg_body_length": 25.789473684210527,
        "avg_word_count": 2.526315789473684,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.05263157894736842,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "joostjager": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "1440000bytes": {
        "total_reviews": 50,
        "avg_body_length": 152.32,
        "avg_word_count": 11.06,
        "avg_code_references": 0.06,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.04,
        "suggestion_rate": 0.06,
        "approval_rate": 0.24,
        "changes_requested_rate": 0.04,
        "is_maintainer": false
      },
      "theschorpioen": {
        "total_reviews": 15,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 1.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 1.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "retropex": {
        "total_reviews": 18,
        "avg_body_length": 55.05555555555556,
        "avg_word_count": 5.277777777777778,
        "avg_code_references": 0.3888888888888889,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.1111111111111111,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "setavenger": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "alfonsoromanz": {
        "total_reviews": 76,
        "avg_body_length": 86.6842105263158,
        "avg_word_count": 9.223684210526315,
        "avg_code_references": 0.19736842105263158,
        "rubber_stamp_rate": 0.02631578947368421,
        "question_rate": 0.0,
        "suggestion_rate": 0.02631578947368421,
        "approval_rate": 0.32894736842105265,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "edilmedeiros": {
        "total_reviews": 32,
        "avg_body_length": 94.5625,
        "avg_word_count": 16.40625,
        "avg_code_references": 0.28125,
        "rubber_stamp_rate": 0.09375,
        "question_rate": 0.03125,
        "suggestion_rate": 0.09375,
        "approval_rate": 0.09375,
        "changes_requested_rate": 0.09375,
        "is_maintainer": false
      },
      "janb84": {
        "total_reviews": 267,
        "avg_body_length": 561.943820224719,
        "avg_word_count": 52.655430711610485,
        "avg_code_references": 0.9438202247191011,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.056179775280898875,
        "suggestion_rate": 0.14232209737827714,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "epiccurious": {
        "total_reviews": 20,
        "avg_body_length": 2.35,
        "avg_word_count": 0.1,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.6,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.65,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "remyers": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "itornaza": {
        "total_reviews": 44,
        "avg_body_length": 341.70454545454544,
        "avg_word_count": 45.20454545454545,
        "avg_code_references": 1.25,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.045454545454545456,
        "suggestion_rate": 0.11363636363636363,
        "approval_rate": 0.8181818181818182,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "yuvicc": {
        "total_reviews": 80,
        "avg_body_length": 329.7,
        "avg_word_count": 32.45,
        "avg_code_references": 1.3,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0125,
        "suggestion_rate": 0.0625,
        "approval_rate": 0.225,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "zaidmstrr": {
        "total_reviews": 58,
        "avg_body_length": 47.172413793103445,
        "avg_word_count": 4.862068965517241,
        "avg_code_references": 0.13793103448275862,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.034482758620689655,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "optout21": {
        "total_reviews": 79,
        "avg_body_length": 33.936708860759495,
        "avg_word_count": 4.189873417721519,
        "avg_code_references": 0.06329113924050633,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "monlovesmango": {
        "total_reviews": 13,
        "avg_body_length": 247.92307692307693,
        "avg_word_count": 33.76923076923077,
        "avg_code_references": 1.6923076923076923,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.15384615384615385,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "angusp": {
        "total_reviews": 49,
        "avg_body_length": 38.83673469387755,
        "avg_word_count": 3.2448979591836733,
        "avg_code_references": 0.08163265306122448,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.02040816326530612,
        "approval_rate": 0.3673469387755102,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "prabhat1308": {
        "total_reviews": 61,
        "avg_body_length": 169.11475409836066,
        "avg_word_count": 17.475409836065573,
        "avg_code_references": 0.6557377049180327,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.06557377049180328,
        "suggestion_rate": 0.06557377049180328,
        "approval_rate": 0.03278688524590164,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "polespinasa": {
        "total_reviews": 158,
        "avg_body_length": 56.60126582278481,
        "avg_word_count": 6.924050632911392,
        "avg_code_references": 0.10759493670886076,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.012658227848101266,
        "suggestion_rate": 0.02531645569620253,
        "approval_rate": 0.0189873417721519,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "am-sq": {
        "total_reviews": 28,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "adamandrews1": {
        "total_reviews": 17,
        "avg_body_length": 16.352941176470587,
        "avg_word_count": 0.8235294117647058,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.17647058823529413,
        "question_rate": 0.0,
        "suggestion_rate": 0.058823529411764705,
        "approval_rate": 0.29411764705882354,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cobratbq": {
        "total_reviews": 16,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "eval-exec": {
        "total_reviews": 26,
        "avg_body_length": 10.846153846153847,
        "avg_word_count": 0.8076923076923077,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.07692307692307693,
        "question_rate": 0.038461538461538464,
        "suggestion_rate": 0.038461538461538464,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "armss9936": {
        "total_reviews": 10,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 1.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 1.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "stringintech": {
        "total_reviews": 50,
        "avg_body_length": 19.3,
        "avg_word_count": 3.2,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.04,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "purplekarrot": {
        "total_reviews": 37,
        "avg_body_length": 0.10810810810810811,
        "avg_word_count": 0.02702702702702703,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "tnndbtc": {
        "total_reviews": 13,
        "avg_body_length": 16,
        "avg_word_count": 1.8461538461538463,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "howhsu": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "a-manning": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "nicolals": {
        "total_reviews": 15,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "frankomosh": {
        "total_reviews": 36,
        "avg_body_length": 8.277777777777779,
        "avg_word_count": 1.2777777777777777,
        "avg_code_references": 0.027777777777777776,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.027777777777777776,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "saikiran57": {
        "total_reviews": 31,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pythcoiner": {
        "total_reviews": 12,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "musaharuna": {
        "total_reviews": 52,
        "avg_body_length": 112.98076923076923,
        "avg_word_count": 11.461538461538462,
        "avg_code_references": 0.2692307692307692,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.038461538461538464,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "mabu44": {
        "total_reviews": 22,
        "avg_body_length": 214.8181818181818,
        "avg_word_count": 25.818181818181817,
        "avg_code_references": 0.6818181818181818,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.18181818181818182,
        "suggestion_rate": 0.045454545454545456,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "shahsb": {
        "total_reviews": 31,
        "avg_body_length": 99.6774193548387,
        "avg_word_count": 13.161290322580646,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.06451612903225806,
        "suggestion_rate": 0.06451612903225806,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "enirox001": {
        "total_reviews": 46,
        "avg_body_length": 212.54347826086956,
        "avg_word_count": 24.130434782608695,
        "avg_code_references": 0.15217391304347827,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.021739130434782608,
        "suggestion_rate": 0.10869565217391304,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "peterwrighten": {
        "total_reviews": 11,
        "avg_body_length": 65.36363636363636,
        "avg_word_count": 9.909090909090908,
        "avg_code_references": 0.18181818181818182,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.18181818181818182,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "waketraindev": {
        "total_reviews": 21,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cedwies": {
        "total_reviews": 26,
        "avg_body_length": 158.8846153846154,
        "avg_word_count": 20.73076923076923,
        "avg_code_references": 0.4230769230769231,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.19230769230769232,
        "suggestion_rate": 0.038461538461538464,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ataraxia009": {
        "total_reviews": 22,
        "avg_body_length": 0.5,
        "avg_word_count": 0.09090909090909091,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "151henry151": {
        "total_reviews": 13,
        "avg_body_length": 24.076923076923077,
        "avg_word_count": 4.153846153846154,
        "avg_code_references": 0.15384615384615385,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "raimo33": {
        "total_reviews": 13,
        "avg_body_length": 0,
        "avg_word_count": 0,
        "avg_code_references": 0,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      }
    },
    "top_by_volume": {
      "maflcko": {
        "total_reviews": 11465,
        "avg_body_length": 61.99877889228085,
        "avg_word_count": 3.632533798517226,
        "avg_code_references": 0.07614478848669864,
        "rubber_stamp_rate": 0.02511993022241605,
        "question_rate": 0.026951591801133885,
        "suggestion_rate": 0.011513301351940688,
        "approval_rate": 0.08102921936327954,
        "changes_requested_rate": 0.005756650675970344,
        "is_maintainer": true
      },
      "hebasto": {
        "total_reviews": 5033,
        "avg_body_length": 170.16530896085834,
        "avg_word_count": 10.616928273395589,
        "avg_code_references": 0.3385654679117822,
        "rubber_stamp_rate": 0.0009934432743890324,
        "question_rate": 0.03934035366580568,
        "suggestion_rate": 0.04490363600238426,
        "approval_rate": 0.287502483608186,
        "changes_requested_rate": 0.016689847009735744,
        "is_maintainer": true
      },
      "achow101": {
        "total_reviews": 4900,
        "avg_body_length": 5.571020408163266,
        "avg_word_count": 0.786530612244898,
        "avg_code_references": 0.011224489795918367,
        "rubber_stamp_rate": 0.0006122448979591836,
        "question_rate": 0.0022448979591836735,
        "suggestion_rate": 0.004489795918367347,
        "approval_rate": 0.004897959183673469,
        "changes_requested_rate": 0.00020408163265306123,
        "is_maintainer": true
      },
      "sipa": {
        "total_reviews": 4641,
        "avg_body_length": 6.509803921568627,
        "avg_word_count": 0.8465847877612583,
        "avg_code_references": 0.019392372333548805,
        "rubber_stamp_rate": 0.0010773540185304892,
        "question_rate": 0.002585649644473174,
        "suggestion_rate": 0.0030165912518853697,
        "approval_rate": 0.0030165912518853697,
        "changes_requested_rate": 0.0,
        "is_maintainer": true
      },
      "ryanofsky": {
        "total_reviews": 4495,
        "avg_body_length": 328.33882091212456,
        "avg_word_count": 38.53125695216907,
        "avg_code_references": 0.8863181312569521,
        "rubber_stamp_rate": 0.005339265850945495,
        "question_rate": 0.04471635150166852,
        "suggestion_rate": 0.27119021134593996,
        "approval_rate": 0.40155728587319245,
        "changes_requested_rate": 0.002224694104560623,
        "is_maintainer": true
      },
      "jonatack": {
        "total_reviews": 3973,
        "avg_body_length": 167.12031210672035,
        "avg_word_count": 17.668764158066953,
        "avg_code_references": 0.33274603574125344,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.022904606091115026,
        "suggestion_rate": 0.07676818525044048,
        "approval_rate": 0.012081550465643092,
        "changes_requested_rate": 0.0005033979360684622,
        "is_maintainer": true
      },
      "promag": {
        "total_reviews": 3252,
        "avg_body_length": 48.40159901599016,
        "avg_word_count": 6.178966789667896,
        "avg_code_references": 0.22386223862238622,
        "rubber_stamp_rate": 0.0012300123001230013,
        "question_rate": 0.07503075030750307,
        "suggestion_rate": 0.08241082410824108,
        "approval_rate": 0.0052275522755227555,
        "changes_requested_rate": 0.004305043050430504,
        "is_maintainer": true
      },
      "jnewbery": {
        "total_reviews": 3128,
        "avg_body_length": 57.429667519181585,
        "avg_word_count": 8.310102301790282,
        "avg_code_references": 0.1729539641943734,
        "rubber_stamp_rate": 0.0025575447570332483,
        "question_rate": 0.020460358056265986,
        "suggestion_rate": 0.06010230179028133,
        "approval_rate": 0.0079923273657289,
        "changes_requested_rate": 0.002877237851662404,
        "is_maintainer": true
      },
      "laanwj": {
        "total_reviews": 3039,
        "avg_body_length": 8.06778545574202,
        "avg_word_count": 0.8538993089832182,
        "avg_code_references": 0.022704837117472853,
        "rubber_stamp_rate": 0.009213557091148404,
        "question_rate": 0.0013162224415926291,
        "suggestion_rate": 0.002303389272787101,
        "approval_rate": 0.06186245475485357,
        "changes_requested_rate": 0.002303389272787101,
        "is_maintainer": true
      },
      "vasild": {
        "total_reviews": 2975,
        "avg_body_length": 127.18050420168068,
        "avg_word_count": 13.345882352941176,
        "avg_code_references": 0.2984873949579832,
        "rubber_stamp_rate": 0.004033613445378151,
        "question_rate": 0.022857142857142857,
        "suggestion_rate": 0.031932773109243695,
        "approval_rate": 0.2,
        "changes_requested_rate": 0.0016806722689075631,
        "is_maintainer": false
      },
      "sjors": {
        "total_reviews": 2900,
        "avg_body_length": 89.71,
        "avg_word_count": 11.927586206896551,
        "avg_code_references": 0.4048275862068966,
        "rubber_stamp_rate": 0.001379310344827586,
        "question_rate": 0.04206896551724138,
        "suggestion_rate": 0.060689655172413794,
        "approval_rate": 0.07620689655172413,
        "changes_requested_rate": 0.00896551724137931,
        "is_maintainer": true
      },
      "fanquake": {
        "total_reviews": 2795,
        "avg_body_length": 195.31914132379248,
        "avg_word_count": 13.305903398926654,
        "avg_code_references": 0.3033989266547406,
        "rubber_stamp_rate": 0.0014311270125223613,
        "question_rate": 0.03005366726296959,
        "suggestion_rate": 0.03041144901610018,
        "approval_rate": 0.3323792486583184,
        "changes_requested_rate": 0.0064400715563506265,
        "is_maintainer": true
      },
      "glozow": {
        "total_reviews": 2498,
        "avg_body_length": 59.650520416333066,
        "avg_word_count": 8.244595676541232,
        "avg_code_references": 0.19935948759007205,
        "rubber_stamp_rate": 0.0012009607686148918,
        "question_rate": 0.03763010408326661,
        "suggestion_rate": 0.04643714971977582,
        "approval_rate": 0.0012009607686148918,
        "changes_requested_rate": 0.00040032025620496394,
        "is_maintainer": true
      },
      "instagibbs": {
        "total_reviews": 2264,
        "avg_body_length": 31.7363074204947,
        "avg_word_count": 3.496024734982332,
        "avg_code_references": 0.04770318021201413,
        "rubber_stamp_rate": 0.007950530035335688,
        "question_rate": 0.007508833922261484,
        "suggestion_rate": 0.019434628975265017,
        "approval_rate": 0.09628975265017668,
        "changes_requested_rate": 0.004858657243816254,
        "is_maintainer": true
      },
      "l0rinc": {
        "total_reviews": 2201,
        "avg_body_length": 256.540208995911,
        "avg_word_count": 26.194457064970468,
        "avg_code_references": 0.2371649250340754,
        "rubber_stamp_rate": 0.011812812358019082,
        "question_rate": 0.030895047705588367,
        "suggestion_rate": 0.0595184007269423,
        "approval_rate": 0.07223989095865516,
        "changes_requested_rate": 0.04770558836892322,
        "is_maintainer": false
      },
      "practicalswift": {
        "total_reviews": 2001,
        "avg_body_length": 4.751124437781109,
        "avg_word_count": 0.5542228885557221,
        "avg_code_references": 0.0074962518740629685,
        "rubber_stamp_rate": 0.004497751124437781,
        "question_rate": 0.0014992503748125937,
        "suggestion_rate": 0.0034982508745627187,
        "approval_rate": 0.014492753623188406,
        "changes_requested_rate": 0.00849575212393803,
        "is_maintainer": false
      },
      "luke-jr": {
        "total_reviews": 1820,
        "avg_body_length": 21.34835164835165,
        "avg_word_count": 2.868131868131868,
        "avg_code_references": 0.04395604395604396,
        "rubber_stamp_rate": 0.06593406593406594,
        "question_rate": 0.026373626373626374,
        "suggestion_rate": 0.01978021978021978,
        "approval_rate": 0.11978021978021978,
        "changes_requested_rate": 0.1686813186813187,
        "is_maintainer": true
      },
      "thestack": {
        "total_reviews": 1796,
        "avg_body_length": 190.41481069042317,
        "avg_word_count": 21.7739420935412,
        "avg_code_references": 0.6080178173719376,
        "rubber_stamp_rate": 0.0011135857461024498,
        "question_rate": 0.05902004454342984,
        "suggestion_rate": 0.10077951002227171,
        "approval_rate": 0.482739420935412,
        "changes_requested_rate": 0.007238307349665924,
        "is_maintainer": false
      },
      "furszy": {
        "total_reviews": 1767,
        "avg_body_length": 110.70401810979061,
        "avg_word_count": 16.14883984153933,
        "avg_code_references": 0.32767402376910015,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.055461233729485006,
        "suggestion_rate": 0.07809847198641766,
        "approval_rate": 0.06960950764006792,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "mzumsande": {
        "total_reviews": 1508,
        "avg_body_length": 117.8236074270557,
        "avg_word_count": 18.066976127320956,
        "avg_code_references": 0.46684350132625996,
        "rubber_stamp_rate": 0.000663129973474801,
        "question_rate": 0.06830238726790451,
        "suggestion_rate": 0.10676392572944297,
        "approval_rate": 0.003978779840848806,
        "changes_requested_rate": 0.000663129973474801,
        "is_maintainer": false
      }
    },
    "top_by_quality": {
      "janb84": {
        "total_reviews": 267,
        "avg_body_length": 561.943820224719,
        "avg_word_count": 52.655430711610485,
        "avg_code_references": 0.9438202247191011,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.056179775280898875,
        "suggestion_rate": 0.14232209737827714,
        "approval_rate": 0.0,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jarolrod": {
        "total_reviews": 362,
        "avg_body_length": 533.3646408839779,
        "avg_word_count": 42.96408839779006,
        "avg_code_references": 1.3977900552486189,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.058011049723756904,
        "suggestion_rate": 0.09668508287292818,
        "approval_rate": 0.19337016574585636,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "shaavan": {
        "total_reviews": 321,
        "avg_body_length": 474.10280373831773,
        "avg_word_count": 63.90965732087228,
        "avg_code_references": 1.7445482866043613,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0778816199376947,
        "suggestion_rate": 0.2523364485981308,
        "approval_rate": 0.514018691588785,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "tdb3": {
        "total_reviews": 501,
        "avg_body_length": 446.560878243513,
        "avg_word_count": 40.942115768463076,
        "avg_code_references": 1.18562874251497,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.03792415169660679,
        "suggestion_rate": 0.0718562874251497,
        "approval_rate": 0.4750499001996008,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "leonardojobim": {
        "total_reviews": 14,
        "avg_body_length": 359.35714285714283,
        "avg_word_count": 33.42857142857143,
        "avg_code_references": 0.9285714285714286,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0,
        "suggestion_rate": 0.0,
        "approval_rate": 0.6428571428571429,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "jamesob": {
        "total_reviews": 923,
        "avg_body_length": 355.2383531960997,
        "avg_word_count": 25.680390032502707,
        "avg_code_references": 0.6933911159263272,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.021668472372697724,
        "suggestion_rate": 0.03466955579631636,
        "approval_rate": 0.13759479956663057,
        "changes_requested_rate": 0.0010834236186348862,
        "is_maintainer": false
      },
      "itornaza": {
        "total_reviews": 44,
        "avg_body_length": 341.70454545454544,
        "avg_word_count": 45.20454545454545,
        "avg_code_references": 1.25,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.045454545454545456,
        "suggestion_rate": 0.11363636363636363,
        "approval_rate": 0.8181818181818182,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "yuvicc": {
        "total_reviews": 80,
        "avg_body_length": 329.7,
        "avg_word_count": 32.45,
        "avg_code_references": 1.3,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0125,
        "suggestion_rate": 0.0625,
        "approval_rate": 0.225,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "ryanofsky": {
        "total_reviews": 4495,
        "avg_body_length": 328.33882091212456,
        "avg_word_count": 38.53125695216907,
        "avg_code_references": 0.8863181312569521,
        "rubber_stamp_rate": 0.005339265850945495,
        "question_rate": 0.04471635150166852,
        "suggestion_rate": 0.27119021134593996,
        "approval_rate": 0.40155728587319245,
        "changes_requested_rate": 0.002224694104560623,
        "is_maintainer": true
      },
      "hodlinator": {
        "total_reviews": 1032,
        "avg_body_length": 327.30232558139534,
        "avg_word_count": 35.406007751937985,
        "avg_code_references": 1.4021317829457365,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.0562015503875969,
        "suggestion_rate": 0.12790697674418605,
        "approval_rate": 0.23352713178294573,
        "changes_requested_rate": 0.016472868217054265,
        "is_maintainer": false
      },
      "rkrux": {
        "total_reviews": 580,
        "avg_body_length": 324.93793103448274,
        "avg_word_count": 36.62413793103448,
        "avg_code_references": 1.1258620689655172,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.06724137931034482,
        "suggestion_rate": 0.14655172413793102,
        "approval_rate": 0.3620689655172414,
        "changes_requested_rate": 0.015517241379310345,
        "is_maintainer": false
      },
      "kouloumos": {
        "total_reviews": 80,
        "avg_body_length": 324,
        "avg_word_count": 39.3125,
        "avg_code_references": 1.5125,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.1125,
        "suggestion_rate": 0.1625,
        "approval_rate": 0.0125,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "pinheadmz": {
        "total_reviews": 531,
        "avg_body_length": 316.6949152542373,
        "avg_word_count": 20.037664783427495,
        "avg_code_references": 0.4783427495291902,
        "rubber_stamp_rate": 0.003766478342749529,
        "question_rate": 0.1487758945386064,
        "suggestion_rate": 0.04143126177024482,
        "approval_rate": 0.2033898305084746,
        "changes_requested_rate": 0.003766478342749529,
        "is_maintainer": false
      },
      "vostrnad": {
        "total_reviews": 13,
        "avg_body_length": 304,
        "avg_word_count": 43.38461538461539,
        "avg_code_references": 0.5384615384615384,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.07692307692307693,
        "suggestion_rate": 0.23076923076923078,
        "approval_rate": 0.07692307692307693,
        "changes_requested_rate": 0.15384615384615385,
        "is_maintainer": false
      },
      "amovfx": {
        "total_reviews": 27,
        "avg_body_length": 290.7037037037037,
        "avg_word_count": 26.77777777777778,
        "avg_code_references": 0.2222222222222222,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.14814814814814814,
        "suggestion_rate": 0.037037037037037035,
        "approval_rate": 0.07407407407407407,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "stickies-v": {
        "total_reviews": 1408,
        "avg_body_length": 287.7052556818182,
        "avg_word_count": 34.15625,
        "avg_code_references": 0.6796875,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.08096590909090909,
        "suggestion_rate": 0.10085227272727272,
        "approval_rate": 0.3039772727272727,
        "changes_requested_rate": 0.0014204545454545455,
        "is_maintainer": false
      },
      "danielabrozzoni": {
        "total_reviews": 125,
        "avg_body_length": 268.064,
        "avg_word_count": 32.008,
        "avg_code_references": 0.672,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.032,
        "suggestion_rate": 0.04,
        "approval_rate": 0.304,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      },
      "cbergqvist": {
        "total_reviews": 93,
        "avg_body_length": 263.0430107526882,
        "avg_word_count": 32.645161290322584,
        "avg_code_references": 1.8064516129032258,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.043010752688172046,
        "suggestion_rate": 0.15053763440860216,
        "approval_rate": 0.40860215053763443,
        "changes_requested_rate": 0.043010752688172046,
        "is_maintainer": false
      },
      "l0rinc": {
        "total_reviews": 2201,
        "avg_body_length": 256.540208995911,
        "avg_word_count": 26.194457064970468,
        "avg_code_references": 0.2371649250340754,
        "rubber_stamp_rate": 0.011812812358019082,
        "question_rate": 0.030895047705588367,
        "suggestion_rate": 0.0595184007269423,
        "approval_rate": 0.07223989095865516,
        "changes_requested_rate": 0.04770558836892322,
        "is_maintainer": false
      },
      "marcofleon": {
        "total_reviews": 245,
        "avg_body_length": 251.1469387755102,
        "avg_word_count": 25.39183673469388,
        "avg_code_references": 0.8448979591836735,
        "rubber_stamp_rate": 0.0,
        "question_rate": 0.036734693877551024,
        "suggestion_rate": 0.061224489795918366,
        "approval_rate": 0.08979591836734693,
        "changes_requested_rate": 0.0,
        "is_maintainer": false
      }
    }
  },
  "pr_size_analysis": {
    "small": {
      "prs": 12476,
      "total_reviews": 39557,
      "reviews_per_pr": 3.170647643475473,
      "avg_body_length": 114.68311550420911,
      "avg_word_count": 10.349040624921,
      "avg_code_references": 0.26144550901231134,
      "rubber_stamp_rate": 0.027580453522764618
    },
    "medium": {
      "prs": 2985,
      "total_reviews": 42779,
      "reviews_per_pr": 14.331323283082076,
      "avg_body_length": 96.14792304635452,
      "avg_word_count": 10.10077374412679,
      "avg_code_references": 0.2527642067369504,
      "rubber_stamp_rate": 0.006966034736669862
    },
    "large": {
      "prs": 379,
      "total_reviews": 7170,
      "reviews_per_pr": 18.91820580474934,
      "avg_body_length": 94.942119944212,
      "avg_word_count": 9.228451882845189,
      "avg_code_references": 0.17587168758716876,
      "rubber_stamp_rate": 0.005718270571827057
    }
  },
  "review_types": {
    "overall": {
      "approved": 14915,
      "changes_requested": 1080,
      "commented": 99052,
      "total": 115047,
      "approval_rate": 0.12964266777925543,
      "changes_requested_rate": 0.009387467730579677
    },
    "maintainers": {
      "approved": 6593,
      "changes_requested": 590,
      "commented": 52500,
      "total": 59683
    },
    "non_maintainers": {
      "approved": 8322,
      "changes_requested": 490,
      "commented": 46552,
      "total": 55364
    }
  },
  "analysis_date": "2025-12-14T20:45:02.766970",
  "total_prs": 23478
}